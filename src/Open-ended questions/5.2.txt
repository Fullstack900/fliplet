To implement asset resizing and compression on the backend while ensuring scalability and handling poor/weak connections, here's an approach we can follow:

Load-Balancing and Horizontal Scaling:

Employ a load balancer to distribute incoming requests across multiple backend servers.
Horizontal scaling involves adding more servers to the system to handle increased load. This can be achieved by using containerization technologies like Docker and orchestrators like Kubernetes.
Asynchronous Processing:

Utilize a message queue system like RabbitMQ or Apache Kafka to decouple the asset resizing and compression tasks from the HTTP request-response cycle.
When a request to download an asset is received, enqueue a message with the necessary details for resizing and compression.
Background Workers:

Implement worker processes that consume messages from the message queue and perform the resizing and compression tasks.
These workers can be horizontally scaled to handle a higher number of concurrent tasks.
Distributed File Storage:

Store the original and processed assets in a distributed file storage system like Amazon S3, Google Cloud Storage, or a distributed file system like GlusterFS or Ceph.
This allows easy access to the files from any backend server and provides fault tolerance and scalability.
Dynamic Generation of Assets:

Instead of pre-generating assets for all possible device screen sizes, generate them dynamically on-demand.
When a worker receives a message from the queue, it can determine the target device's screen size and generate the appropriate resized or compressed asset.
Caching:

Implement a caching layer using tools like Redis or Varnish to cache frequently accessed assets.
Caching reduces the load on the backend by serving the assets directly from the cache if available.
Progressive Downloads:

Enable progressive downloads to handle poor or weak connections effectively.
Stream the asset data in small chunks instead of waiting for the entire asset to be downloaded.
This allows users to start viewing the asset while it is being downloaded gradually.
Data Integrity and Error Handling:

Implement checksum verification mechanisms like MD5 or SHA-256 to ensure the downloaded files are not corrupted.
Calculate the checksum of the original file on the server and compare it with the checksum of the downloaded file on the client side.
If a checksum mismatch occurs, initiate a retry mechanism or send an error response to the client.
By following these guidelines, we can build a scalable backend system that efficiently handles asset resizing and compression while considering poor network conditions and ensuring the integrity of downloaded files.